### 🛠 기술 스택

---

- Spring, Spring Boot, Spring Batch, Spring Data JPA, MySQL, MongoDB, Kafka, Zookeeper

### 📖 프로젝트 소개

---

이전에 수행했던 [**BUDDA 프로젝트**](https://github.com/naver0504/comprehensive-design)에서는 대략 130만 건의 아파트 실거래 매매 데이터를 조회하는 시스템을 구축하였습니다.

기존 성능 최적화에 그치지 않고, 더 나은 성능을 위해 **CQRS 패턴**을 도입하여 조회 서비스를 **MongoDB**를 활용해 읽기 전용으로 분리하였습니다. 이를 통해 조회 성능을 획기적으로 개선하였습니다.

또한, 새로운 아파트 실거래 매매 데이터를 지속적으로 수집하고 저장하는 배치 스케줄러를 구현하였으며,  이 과정에서 **Message Queue**로 **Kafka**를 사용했습니다. 

### 🎛️ 시스템 아키텍쳐

---

![enhance budda](https://github.com/user-attachments/assets/901e47aa-d223-4ae2-b350-aadb4f863f6a)

### 🙋‍♂️ 개선 사항

---

1. **아파트 실거래가 데이터 조회 성능 개선**
    - 아파트 실거래가 데이터를 조회하는 과정에서 가장 큰 성능 병목은 **Join 연산에서 발생하는 높은 비용**이었습니다. 이를 해결하기 위해 역정규화를 수행하여, 데이터를 조회 전용 형태로 변환함으로써 Join 연산의 부담을 줄였습니다.
        
        이러한 방식을 적용한 결과, 조회 성능이 크게 향상되어 **1000페이지 기준 조회 시간이 0.5초에서 0.03초로**, **10000페이지 기준 5초 이상 소요되던 것을 0.33초로 단축**하는 성과를 거두었습니다.
        
    - **Count 쿼리의 성능이 일반 페이징 조회보다 더 오래 걸리는 문제**가 발생하여 **Count 쿼리에 대한 캐시**를 도입했습니다. 초기에는 **Redis를 활용한 글로벌 캐시**와 로컬 캐시를 비교 검토하였으나, 속도와 메모리 사용 측면에서 우수한 **로컬 캐시**를 도입하기로 결정했습니다.
        
        로컬 캐시로는 **EhCache**와 **Caffeine Cache**를 벤치마크 표를 참고하여 비교하였습니다. 그 결과, **Caffeine Cache**가 메모리 효율성과 속도 면에서 모두 우수하다는 것을 확인했습니다. **EhCache**의 경우 커스터마이징 가능성이 큰 장점이 있었으나, 복잡한 캐시 구조가 필요하지 않은 상황이었기에 **성능**을 고려하여 **Caffeine Cache**를 사용했습니다. 이를 통해 **Count 쿼리 요청에도 빠르고 안정적인 응답 속도**를 확보할 수 있었으며, 데이터베이스 부하를 크게 줄일 수 있었습니다.
2. **신규 아파트 실거래 매매 데이터 저장**
   
    **신규 아파트 실거래 매매 데이터**를 **자동으로 수집 및 저장**하는 배치 작업을 구현했습니다.
    - 매달 1일 오전 5시에 스케줄링되어 **국토교통부 API를 통해 실거래 데이터를 수집**하고, 수집한 데이터에 **좌표 데이터와 금리 설정을 추가**하여 모델에 예측값을 갱신 및 저장하는 작업을 수행합니다. 이후, **Kafka를 통해 수집된 데이터를 전달**하고, **Query-Service에서 Event를 수신하여 해당 트랜잭션을 저장**하는 구조로 설계하였습니다.
    - 이 과정에서 **Event를 Produce하는 Batch 작업**을 구현할 때, **KafkaItemWriter**를 고려했으나, 해당 Writer에서는 **토픽(Topic)을 설정하는 부분이 없는 문제**를 확인했습니다. 이를 해결하기 위해, **KeyValueItemWriter를 상속하여 CustomKafkaItemWriter를 구현**하고, **토픽을 별도로 설정할 수 있는 Writer**를 만들어 문제를 해결했습니다.
### 🧐 느낀 점

---

MongoDB를 활용하여 조회와 저장 서비스를 분리하면서 어쩌면, 단일 책임 원칙이라고도 할 수 있는 **서비스 역할 분리 구조**를 적용할 수 있었습니다. 각 서비스가 명확하게 분리됨으로써 역할과 책임이 명확해졌고, 조회 성능과 데이터 일관성을 모두 확보할 수 있었습니다.

하지만 이러한 구조적 개선에는 **Trade-Off**도 있었습니다. Kafka, Zookeeper, MongoDB 등 여러 컴포넌트를 활용하다 보니 시스템 전반의 **메모리 사용량이 약 200MB 증가**하는 것을 확인했습니다. 성능을 개선한다고 해서 속도만 빨라지는 것이 반드시 좋은 것은 아니며, 그에 따른 **시스템 자원 사용 증가와 관리 복잡성**을 반드시 고려해야 한다는 점을 느꼈습니다.

이러한 경험을 통해 성능 최적화를 위해서는 단순히 처리 속도를 높이는 것뿐만 아니라, **다른 리소스 사용의 증가와 시스템 안정성**을 종합적으로 판단해야 함을 깨달았습니다. 앞으로는 각 프로젝트의 목적과 요구사항을 고려하여 **성능 개선과 리소스 사용의 균형을 맞춘 설계**를 고민해야 한다고 생각합니다.
